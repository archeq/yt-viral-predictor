# YouTube Viral Video Predictor
## Projekt z przedmiotu: Uczenie Maszynowe

---

## 1. Opis Projektu

### Temat
**Predykcja wiralowoÅ›ci filmÃ³w na YouTube na podstawie miniaturek i tytuÅ‚Ã³w**

### Cel
Stworzenie modelu uczenia maszynowego, ktÃ³ry na podstawie miniaturki (obrazu) i tytuÅ‚u (tekstu) przewiduje, czy film na YouTube ma potencjaÅ‚ stania siÄ™ viralem.

### Kontekst
TwÃ³rcy treÅ›ci na YouTube czÄ™sto zastanawiajÄ… siÄ™, jakie elementy sprawiajÄ…, Å¼e film staje siÄ™ popularny. Ten projekt wykorzystuje deep learning do analizy dwÃ³ch kluczowych elementÃ³w widocznych przed klikniÄ™ciem:
- **Miniaturka** - pierwszy element wizualny przyciÄ…gajÄ…cy uwagÄ™
- **TytuÅ‚** - tekst zachÄ™cajÄ…cy do obejrzenia

---

## 2. Opis Problemu

### Rodzaj zadania
Regresja znormalizowana lub soft ranking - model przewiduje ciÄ…gÅ‚y wynik wiralowoÅ›ci w zakresie [0, 1], gdzie wartoÅ›ci bliskie 1 oznaczajÄ… wyÅ¼szy potencjaÅ‚ viralowy.

### Definicja matematyczna

Niech:
- $x_{img} \in \mathbb{R}^{224 \times 224 \times 3}$ - miniaturka filmu (obraz RGB)
- $x_{txt} \in \mathbb{N}^{L}$ - tytuÅ‚ filmu (sekwencja tokenÃ³w o dÅ‚ugoÅ›ci L)
- $y \in \[0, 1\]$ - etykieta (0 = sÅ‚aby wynik, 1 = viral)

Model $f_\theta$ przewiduje:
$$\hat{y} = f_\theta(x_{img}, x_{txt}) = \sigma(g(h_{img}(x_{img}) \oplus h_{txt}(x_{txt})))$$

gdzie:
- $h_{img}: \mathbb{R}^{224 \times 224 \times 3} \rightarrow \mathbb{R}^{2048}$ - ekstraktor cech wizualnych (ResNet50)
- $h_{txt}: \mathbb{N}^{L} \rightarrow \mathbb{R}^{768}$ - ekstraktor cech tekstowych (DistilBERT)
- $\oplus$ - konkatenacja wektorÃ³w
- $g: \mathbb{R}^{2816} \rightarrow \mathbb{R}$ - klasyfikator (MLP)
- $\sigma$ - funkcja sigmoidalna

### Metryka wiralowoÅ›ci (V-Score)

Do okreÅ›lenia, czy film jest viralem, uÅ¼ywamy **logarytmicznego V-Score** - znormalizowanej miary wydajnoÅ›ci filmu wzglÄ™dem historycznej Å›redniej kanaÅ‚u:

$$V_{score} = \frac{\log(views + 1) - \mu_{baseline}}{\sigma_{baseline}}$$

gdzie:
- $\mu_{baseline}$ - mediana logarytmu wyÅ›wietleÅ„ z ostatnich 30 filmÃ³w kanaÅ‚u
- $\sigma_{baseline}$ - odchylenie standardowe logarytmu wyÅ›wietleÅ„

**Interpretacja:**
| V-Score | Ocena |
|---------|--------------|
| > 1.0 | Viral  |
| < -0.5 | SÅ‚aby wynik  |

---

## 3. Dane WejÅ›ciowe i WyjÅ›ciowe

### Å¹rÃ³dÅ‚o danych
- **YouTube Data API v3** - wyszukiwanie kanaÅ‚Ã³w po niszach
- **yt-dlp** - pobieranie metadanych filmÃ³w (tytuÅ‚y, wyÅ›wietlenia, miniaturki)

### Format danych

#### Pliki CSV (`data/raw/{channel_id}.csv`)
| Kolumna | Typ | Opis |
|---------|-----|------|
| Video ID | string | Unikalny identyfikator filmu |
| Title | string | TytuÅ‚ filmu |
| Current Views | int | Liczba wyÅ›wietleÅ„ |
| V-Score | float | Obliczony wskaÅºnik wiralowoÅ›ci |

#### Miniaturki (`data/raw/thumbnails/{video_id}.jpg`)
- Format: JPEG
- RozdzielczoÅ›Ä‡: rÃ³Å¼na (skalowana do 224x224 podczas treningu)

### PodziaÅ‚ danych
- Dane sÄ… **balansowane** poprzez undersampling (rÃ³wna liczba virali i sÅ‚abych filmÃ³w)
- PodziaÅ‚: **90% trening, 10% test** (stratified split - zachowuje proporcje klas)

### Replikacja danych

```bash
# 1. Ustaw klucz API YouTube w pliku api.txt
echo "YOUR_API_KEY" > api.txt

# 2. Uruchom pobieranie danych
python main.py

# 3. Dane zostanÄ… zapisane w:
#    - data/raw/*.csv (metadane)
#    - data/raw/thumbnails/*.jpg (miniaturki)
```

---

## 4. Opis Algorytmu

### Architektura modelu (Multimodal Fusion)

Model Å‚Ä…czy dwie gaÅ‚Ä™zie przetwarzania:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Miniaturka    â”‚     â”‚     TytuÅ‚       â”‚
â”‚  (224Ã—224Ã—3)    â”‚     â”‚   (max 50 tok)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚
         â–¼                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    ResNet50     â”‚     â”‚   DistilBERT    â”‚
â”‚   (frozen)      â”‚     â”‚    (frozen)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚
         â–¼                       â–¼
    [2048 dim]              [768 dim]
         â”‚                       â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚ Concatenate â”‚
              â”‚  [2816 dim] â”‚
              â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚ Linear(1024) â”‚
              â”‚  BatchNorm   â”‚
              â”‚    ReLU      â”‚
              â”‚ Dropout(0.5) â”‚
              â”‚ Linear(256)  â”‚
              â”‚  BatchNorm   â”‚
              â”‚    ReLU      â”‚
              â”‚ Dropout(0.3) â”‚
              â”‚  Linear(1)   â”‚
              â”‚   Sigmoid    â”‚
              â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
              [Probability]
```

### Komponenty modelu

#### 1. GaÅ‚Ä…Åº wizualna (ResNet50)
- **Architektura**: ResNet50 z wagami ImageNet (zamroÅ¼ony)
- **WyjÅ›cie**: wektor 2048 cech
- **Transformacje wejÅ›cia (trening)**:
  - Resize do 256Ã—256, RandomCrop do 224Ã—224
  - RandomHorizontalFlip, ColorJitter, RandomRotation
  - RandomGrayscale, RandomErasing
  - Normalizacja: mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]

#### 2. GaÅ‚Ä…Åº tekstowa (DistilBERT)
- **Architektura**: DistilBERT-base-uncased (zamroÅ¼ony)
- **WyjÅ›cie**: token [CLS] â†’ wektor 768 cech
- **Tokenizacja**: max_length=50, padding, truncation

#### 3. Klasyfikator (MLP z BatchNorm)
```python
self.classifier = nn.Sequential(
    nn.Linear(2816, 1024),
    nn.BatchNorm1d(1024),
    nn.ReLU(),
    nn.Dropout(0.5),
    nn.Linear(1024, 256),
    nn.BatchNorm1d(256),
    nn.ReLU(),
    nn.Dropout(0.3),
    nn.Linear(256, 1),
    nn.Sigmoid()
)
```

### Funkcja kosztu

**Binary Cross-Entropy Loss (BCE)**: 

$$\mathcal{L} = -\frac{1}{N}\sum_{i=1}^{N}[y_i \log(\hat{y}_i) + (1-y_i)\log(1-\hat{y}_i)]$$

**Uwaga**: Pomimo uÅ¼ycia BCE, model przewiduje **ciÄ…gÅ‚y wynik wiralowoÅ›ci** (nie dyskretnÄ… klasÄ™). BCE dziaÅ‚a jako funkcja kosztu dla **regresji z sigmoidÄ…**, karzÄ…c za odlegÅ‚oÅ›Ä‡ predykcji od znormalizowanego celu.

### Algorytm optymalizacji

**Adam Optimizer** z **ReduceLROnPlateau scheduler**:
- Automatycznie zmniejsza LR gdy model przestaje siÄ™ poprawiaÄ‡

**Hiperparametry**:
- Learning rate: $\alpha = 3 \times 10^{-4}$ (tylko klasyfikator)
- Weight decay: $1 \times 10^{-3}$ (regularyzacja L2)
- $\beta_1 = 0.9$, $\beta_2 = 0.999$
- Batch size: 16
- Early stopping patience: 10 epok

### Techniki regularyzacji

1. **Frozen backbone** - ResNet50 i DistilBERT sÄ… zamroÅ¼one
2. **Dropout** - 0.5 po pierwszej warstwie, 0.3 po drugiej
3. **BatchNorm** - normalizacja miÄ™dzy warstwami
4. **Data Augmentation** - augmentacja obrazÃ³w treningowych
5. **Weight decay** - regularyzacja L2

### Proces treningu

1. **ZaÅ‚adowanie danych** z CSV i miniaturek
2. **Filtrowanie** - usuniÄ™cie "Å›redniakÃ³w" (tylko V-Score > 1.0 lub < -0.5)
3. **Balansowanie** - undersampling do rÃ³wnej liczby klas
4. **PodziaÅ‚** - 90% trening, 10% test (stratified)
5. **Forward pass** - obliczenie predykcji
6. **Backward pass** - propagacja gradientÃ³w (tylko klasyfikator)
7. **Early stopping** - zatrzymanie gdy accuracy nie roÅ›nie przez 10 epok

### Uruchomienie projektu

```bash
# Instalacja zaleÅ¼noÅ›ci
pip install -r requirements.txt

# Pobieranie danych (opcjonalne - jeÅ›li nie ma danych)
python main.py

# Trening modelu
python train.py

# Model zostanie zapisany do: data/models/viral_predictor.pth
```

---

## 5. Wyniki i Wnioski

### Metryki treningu (z Early Stopping)

| Epoka | Train Loss | Test Loss | Test Accuracy |
|-------|------------|-----------|---------------|
| 1 | 0.69 | 0.67 | 58.75% |
| 2 | 0.60 | 0.62 | 64.83% â˜… Best |
| 3 | 0.44 | 0.65 | 67.40% |
| ... | ... | ... | ... |
| 7 | 0.11 | 0.97 | 69.43% |

**Early stopping** zatrzymaÅ‚ trening w epoce 7 (patience=5), najlepszy model z epoki 2.

### KoÅ„cowe wyniki

- **Test Loss**: 0.62
- **Test Accuracy**: ~65-70%

### PrzykÅ‚adowe predykcje

| Miniaturka | TytuÅ‚ | Predykcja |
|------------|-------|-----------|
| ðŸ–¼ï¸ Jasne kolory, twarz | "SHOCKING Discovery..." | 78% (viral) |
| ðŸ–¼ï¸ Ciemne, nudne | "Tutorial part 5" | 32% (nie-viral) |

### Analiza

**Czynniki wpÅ‚ywajÄ…ce na wiralowoÅ›Ä‡:**
1. **Miniaturki**: jasne kolory, twarze z emocjami, duÅ¼y tekst
2. **TytuÅ‚y**: sÅ‚owa kluczowe ("SHOCKING", "NEW", liczby), emocjonalny jÄ™zyk

**Ograniczenia:**
- Model nie uwzglÄ™dnia treÅ›ci samego filmu
- ZaleÅ¼noÅ›Ä‡ od specyfiki kanaÅ‚u (V-Score normalizuje, ale nisze sÄ… rÃ³Å¼ne)
- Ograniczona iloÅ›Ä‡ danych treningowych

### Wnioski

1. **Multimodalne podejÅ›cie** (obraz + tekst) pozwala na analizÄ™ obu elementÃ³w
2. **V-Score** jako metryka jest bardziej sprawiedliwa niÅ¼ surowe wyÅ›wietlenia
3. **Transfer learning z frozen backbone** zapobiega overfittingowi na maÅ‚ym zbiorze
4. **Data Augmentation** zwiÄ™ksza efektywnÄ… iloÅ›Ä‡ danych treningowych
5. **Early stopping** chroni przed przeuczeniem modelu

---

## Struktura projektu

```
yt-viral-predictor/
â”œâ”€â”€ main.py                    # GÅ‚Ã³wny skrypt pobierania danych
â”œâ”€â”€ download.py                # Klasa DataDownloader (API + yt-dlp)
â”œâ”€â”€ dataset.py                 # PyTorch Dataset
â”œâ”€â”€ model.py                   # Architektura ViralPredictor
â”œâ”€â”€ train.py                   # Skrypt treningowy
â”œâ”€â”€ api.txt                    # Klucz YouTube API (nie commitowaÄ‡!)
â”œâ”€â”€ requirements.txt           # ZaleÅ¼noÅ›ci Python
â”œâ”€â”€ data/   
â”‚   â”œâ”€â”€ raw/                   # Surowe dane (CSV + miniaturki)
â”‚   â””â”€â”€ models/                # Wytrenowane modele (.pth)
â””â”€â”€ docs/                      # Dokumentacja projektu
    â”œâ”€â”€ V-SCORE.md             # Dokumentacja algorytmu V-Score
    â””â”€â”€ PRESENTATION-pl.md     # Ten dokument
```

---

## Wymagane biblioteki

```
torch
torchvision
transformers
pandas
numpy
Pillow
yt-dlp
google-api-python-client
tqdm
```

---


Projekt wykonany w ramach przedmiotu **Uczenie Maszynowe** (UAM 2025/2026)
